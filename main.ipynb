{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "56d6f0d8",
      "metadata": {
        "id": "56d6f0d8",
        "outputId": "e79dd03e-a877-4323-8e29-b2b1117a2f80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'archive/tmdb_5000_movies.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4032785641.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Import the TMDB dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmovies_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'archive/tmdb_5000_movies.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mcredits_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'archive/tmdb_5000_credits.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'archive/tmdb_5000_movies.csv'"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Import the TMDB dataset\n",
        "movies_df = pd.read_csv('content/tmdb_5000_movies.csv')\n",
        "credits_df = pd.read_csv('conent/tmdb_5000_credits.csv')\n",
        "\n",
        "# Display basic information about the datasets\n",
        "print(\"Movies Dataset Shape:\", movies_df.shape)\n",
        "print(\"\\nCredits Dataset Shape:\", credits_df.shape)\n",
        "\n",
        "print(\"\\nMovies Dataset Columns:\")\n",
        "print(movies_df.columns.tolist())\n",
        "\n",
        "print(\"\\nCredits Dataset Columns:\")\n",
        "print(credits_df.columns.tolist())\n",
        "\n",
        "# Display first few rows of movies dataset\n",
        "print(\"\\nFirst 5 rows of Movies Dataset:\")\n",
        "movies_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5fd2df87",
      "metadata": {
        "id": "5fd2df87"
      },
      "outputs": [],
      "source": [
        "# Data Cleaning Analysis - Step 1: Identify Issues\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"DATA QUALITY ASSESSMENT\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# 1. Check for missing values\n",
        "print(\"\\n1. MISSING VALUES IN MOVIES DATASET:\")\n",
        "print(\"-\" * 60)\n",
        "missing_movies = movies_df.isnull().sum()\n",
        "missing_pct = (missing_movies / len(movies_df)) * 100\n",
        "missing_summary = pd.DataFrame({\n",
        "    'Missing Count': missing_movies,\n",
        "    'Percentage': missing_pct\n",
        "})\n",
        "print(missing_summary[missing_summary['Missing Count'] > 0].sort_values('Missing Count', ascending=False))\n",
        "\n",
        "print(\"\\n2. MISSING VALUES IN CREDITS DATASET:\")\n",
        "print(\"-\" * 60)\n",
        "missing_credits = credits_df.isnull().sum()\n",
        "print(missing_credits[missing_credits > 0])\n",
        "\n",
        "# 3. Check for duplicates\n",
        "print(\"\\n3. DUPLICATE ROWS:\")\n",
        "print(\"-\" * 60)\n",
        "print(f\"Duplicates in movies_df: {movies_df.duplicated().sum()}\")\n",
        "print(f\"Duplicates in credits_df: {credits_df.duplicated().sum()}\")\n",
        "\n",
        "# 4. Check data types\n",
        "print(\"\\n4. DATA TYPES:\")\n",
        "print(\"-\" * 60)\n",
        "print(movies_df.dtypes)\n",
        "\n",
        "# 5. Check for zero/invalid values in numerical columns\n",
        "print(\"\\n5. ZERO VALUES IN KEY COLUMNS:\")\n",
        "print(\"-\" * 60)\n",
        "print(f\"Movies with budget = 0: {(movies_df['budget'] == 0).sum()}\")\n",
        "print(f\"Movies with revenue = 0: {(movies_df['revenue'] == 0).sum()}\")\n",
        "print(f\"Movies with runtime = 0: {(movies_df['runtime'] == 0).sum()}\")\n",
        "\n",
        "# 6. Basic statistics\n",
        "print(\"\\n6. BASIC STATISTICS:\")\n",
        "print(\"-\" * 60)\n",
        "movies_df.describe()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76e3202b",
      "metadata": {
        "id": "76e3202b"
      },
      "outputs": [],
      "source": [
        "# Data Cleaning - Step 1: Handle Missing Values and Zero Values\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"DATA CLEANING - STEP 1\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Create a copy of the original data for cleaning\n",
        "movies_cleaned = movies_df.copy()\n",
        "credits_cleaned = credits_df.copy()\n",
        "\n",
        "print(f\"Original dataset shape: {movies_cleaned.shape}\")\n",
        "\n",
        "# 1. Handle zero values in critical columns (these are likely missing data, not actual zeros)\n",
        "print(\"\\n1. HANDLING ZERO VALUES:\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "# Replace 0 values with NaN for budget, revenue, runtime\n",
        "movies_cleaned['budget'] = movies_cleaned['budget'].replace(0, np.nan)\n",
        "movies_cleaned['revenue'] = movies_cleaned['revenue'].replace(0, np.nan)\n",
        "movies_cleaned['runtime'] = movies_cleaned['runtime'].replace(0, np.nan)\n",
        "\n",
        "print(f\"Budget 0s replaced with NaN: {(movies_df['budget'] == 0).sum()}\")\n",
        "print(f\"Revenue 0s replaced with NaN: {(movies_df['revenue'] == 0).sum()}\")\n",
        "print(f\"Runtime 0s replaced with NaN: {(movies_df['runtime'] == 0).sum()}\")\n",
        "\n",
        "# 2. Handle missing values in non-critical columns\n",
        "print(\"\\n2. HANDLING MISSING VALUES:\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "# Fill missing values for non-critical columns\n",
        "movies_cleaned['homepage'].fillna('No homepage available', inplace=True)\n",
        "movies_cleaned['tagline'].fillna('No tagline available', inplace=True)\n",
        "movies_cleaned['overview'].fillna('No overview available', inplace=True)\n",
        "\n",
        "print(\"Missing values filled for homepage, tagline, overview\")\n",
        "\n",
        "# 3. Remove rows with critical missing data\n",
        "print(\"\\n3. REMOVING ROWS WITH CRITICAL MISSING DATA:\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "# Remove rows where all financial data is missing\n",
        "before_removal = len(movies_cleaned)\n",
        "movies_cleaned = movies_cleaned.dropna(subset=['release_date'])  # Remove if no release date\n",
        "after_removal = len(movies_cleaned)\n",
        "\n",
        "print(f\"Rows removed due to missing release_date: {before_removal - after_removal}\")\n",
        "print(f\"Final dataset shape: {movies_cleaned.shape}\")\n",
        "\n",
        "# 4. Check remaining missing values\n",
        "print(\"\\n4. REMAINING MISSING VALUES:\")\n",
        "print(\"-\" * 40)\n",
        "remaining_missing = movies_cleaned.isnull().sum()\n",
        "print(remaining_missing[remaining_missing > 0])\n",
        "\n",
        "print(\"\\n✅ Data Cleaning Step 1 Complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32fc5ad5",
      "metadata": {
        "id": "32fc5ad5"
      },
      "outputs": [],
      "source": [
        "# Data Cleaning - Step 2: Data Type Conversion and JSON Parsing\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"DATA CLEANING - STEP 2\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "import json\n",
        "import ast\n",
        "\n",
        "# 1. Convert release_date to datetime\n",
        "print(\"1. CONVERTING DATA TYPES:\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "movies_cleaned['release_date'] = pd.to_datetime(movies_cleaned['release_date'], errors='coerce')\n",
        "print(\"✅ release_date converted to datetime\")\n",
        "\n",
        "# 2. Parse JSON columns for better analysis\n",
        "print(\"\\n2. PARSING JSON COLUMNS:\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "def parse_json_column(df, column_name):\n",
        "    \"\"\"Parse JSON string columns and extract useful information\"\"\"\n",
        "    try:\n",
        "        # Parse JSON strings\n",
        "        parsed_data = df[column_name].apply(lambda x: ast.literal_eval(x) if pd.notna(x) else [])\n",
        "\n",
        "        # Extract names from JSON objects\n",
        "        if column_name == 'genres':\n",
        "            # For genres: extract genre names\n",
        "            df[f'{column_name}_parsed'] = parsed_data.apply(\n",
        "                lambda x: [item['name'] for item in x if isinstance(item, dict) and 'name' in item]\n",
        "            )\n",
        "        elif column_name in ['production_companies', 'production_countries']:\n",
        "            # For production: extract names\n",
        "            df[f'{column_name}_parsed'] = parsed_data.apply(\n",
        "                lambda x: [item['name'] for item in x if isinstance(item, dict) and 'name' in item]\n",
        "            )\n",
        "        elif column_name == 'spoken_languages':\n",
        "            # For languages: extract language names\n",
        "            df[f'{column_name}_parsed'] = parsed_data.apply(\n",
        "                lambda x: [item['name'] for item in x if isinstance(item, dict) and 'name' in item]\n",
        "            )\n",
        "        elif column_name == 'keywords':\n",
        "            # For keywords: extract keyword names\n",
        "            df[f'{column_name}_parsed'] = parsed_data.apply(\n",
        "                lambda x: [item['name'] for item in x if isinstance(item, dict) and 'name' in item]\n",
        "            )\n",
        "\n",
        "        print(f\"✅ {column_name} parsed successfully\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error parsing {column_name}: {e}\")\n",
        "        return False\n",
        "\n",
        "# Parse JSON columns\n",
        "json_columns = ['genres', 'keywords', 'production_companies', 'production_countries', 'spoken_languages']\n",
        "for col in json_columns:\n",
        "    parse_json_column(movies_cleaned, col)\n",
        "\n",
        "# 3. Parse cast and crew from credits dataset\n",
        "print(\"\\n3. PARSING CREDITS DATA:\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "def parse_cast_crew(credits_df):\n",
        "    \"\"\"Parse cast and crew information\"\"\"\n",
        "    try:\n",
        "        # Parse cast\n",
        "        credits_df['cast_parsed'] = credits_df['cast'].apply(\n",
        "            lambda x: ast.literal_eval(x) if pd.notna(x) else []\n",
        "        )\n",
        "\n",
        "        # Extract top 3 actors from cast\n",
        "        credits_df['top_actors'] = credits_df['cast_parsed'].apply(\n",
        "            lambda x: [actor['name'] for actor in x[:3] if isinstance(actor, dict) and 'name' in actor]\n",
        "        )\n",
        "\n",
        "        # Parse crew\n",
        "        credits_df['crew_parsed'] = credits_df['crew'].apply(\n",
        "            lambda x: ast.literal_eval(x) if pd.notna(x) else []\n",
        "        )\n",
        "\n",
        "        # Extract director from crew\n",
        "        credits_df['director'] = credits_df['crew_parsed'].apply(\n",
        "            lambda x: next((person['name'] for person in x if person.get('job') == 'Director'), 'Unknown')\n",
        "        )\n",
        "\n",
        "        print(\"✅ Cast and crew data parsed successfully\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error parsing credits: {e}\")\n",
        "        return False\n",
        "\n",
        "parse_cast_crew(credits_cleaned)\n",
        "\n",
        "print(\"\\n✅ Data Cleaning Step 2 Complete!\")\n",
        "print(f\"Cleaned movies dataset shape: {movies_cleaned.shape}\")\n",
        "print(f\"Cleaned credits dataset shape: {credits_cleaned.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53defbc4",
      "metadata": {
        "id": "53defbc4"
      },
      "outputs": [],
      "source": [
        "# Data Cleaning - Step 3: Merge Datasets and Create Features for Recommendation System\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"DATA CLEANING - STEP 3\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# 1. Merge movies and credits datasets\n",
        "print(\"1. MERGING DATASETS:\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "# Merge on movie_id and id\n",
        "merged_df = movies_cleaned.merge(credits_cleaned, left_on='id', right_on='movie_id', how='left')\n",
        "print(f\"✅ Datasets merged successfully\")\n",
        "print(f\"Merged dataset shape: {merged_df.shape}\")\n",
        "\n",
        "# Check column names after merge to understand the naming\n",
        "print(f\"Columns after merge: {list(merged_df.columns)}\")\n",
        "\n",
        "# 2. Create new features for recommendation system\n",
        "print(\"\\n2. CREATING RECOMMENDATION FEATURES:\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "# Calculate profit (revenue - budget)\n",
        "merged_df['profit'] = merged_df['revenue'] - merged_df['budget']\n",
        "merged_df['profit_margin'] = merged_df['profit'] / merged_df['budget'].replace(0, np.nan)\n",
        "\n",
        "# Create year feature from release_date\n",
        "merged_df['year'] = merged_df['release_date'].dt.year\n",
        "\n",
        "# Create decade feature\n",
        "merged_df['decade'] = (merged_df['year'] // 10) * 10\n",
        "\n",
        "# Calculate popularity score (normalized)\n",
        "merged_df['popularity_normalized'] = (merged_df['popularity'] - merged_df['popularity'].min()) / (merged_df['popularity'].max() - merged_df['popularity'].min())\n",
        "\n",
        "# Create genre count\n",
        "merged_df['genre_count'] = merged_df['genres_parsed'].apply(lambda x: len(x) if isinstance(x, list) else 0)\n",
        "\n",
        "# Create text features for content-based filtering\n",
        "# Use the correct title column name (from movies dataset, not credits)\n",
        "merged_df['combined_text'] = (\n",
        "    merged_df['overview'].fillna('') + ' ' +\n",
        "    merged_df['tagline'].fillna('') + ' ' +\n",
        "    merged_df['original_title'].fillna('')  # Use original_title instead of title\n",
        ")\n",
        "\n",
        "print(\"✅ New features created:\")\n",
        "print(\"  - profit, profit_margin\")\n",
        "print(\"  - year, decade\")\n",
        "print(\"  - popularity_normalized\")\n",
        "print(\"  - genre_count\")\n",
        "print(\"  - combined_text (for content-based filtering)\")\n",
        "\n",
        "# 3. Final data quality check\n",
        "print(\"\\n3. FINAL DATA QUALITY CHECK:\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "print(f\"Final dataset shape: {merged_df.shape}\")\n",
        "print(f\"Final missing values:\")\n",
        "final_missing = merged_df.isnull().sum()\n",
        "print(final_missing[final_missing > 0])\n",
        "\n",
        "# 4. Display sample of cleaned data\n",
        "print(\"\\n4. SAMPLE OF CLEANED DATA:\")\n",
        "print(\"-\" * 40)\n",
        "print(\"Sample movies with key features:\")\n",
        "sample_cols = ['original_title', 'year', 'genres_parsed', 'director', 'vote_average', 'budget', 'revenue', 'profit']\n",
        "print(merged_df[sample_cols].head())\n",
        "\n",
        "print(\"\\n✅ Data Cleaning Complete! Dataset ready for recommendation system development.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "4272c2eb",
      "metadata": {
        "id": "4272c2eb",
        "outputId": "a43391af-0340-4c70-a4f4-80ce8de1812a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "DATA ANALYSIS AND VISUALIZATION\n",
            "============================================================\n",
            "1. BASIC STATISTICS OVERVIEW:\n",
            "--------------------------------------------------\n",
            "💰 FINANCIAL STATISTICS:\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'merged_df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3728041466.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Financial statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"💰 FINANCIAL STATISTICS:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Average Budget: ${merged_df['budget'].mean():,.0f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Average Revenue: ${merged_df['revenue'].mean():,.0f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Average Profit: ${merged_df['profit'].mean():,.0f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'merged_df' is not defined"
          ]
        }
      ],
      "source": [
        "# Data Analysis and Visualization - Part 1: Basic Statistics and Distribution\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"DATA ANALYSIS AND VISUALIZATION\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Set up plotting style\n",
        "plt.style.use('default')\n",
        "plt.rcParams['figure.figsize'] = (18, 12)\n",
        "plt.rcParams['font.size'] = 10\n",
        "\n",
        "# 1. Basic Statistics Overview\n",
        "print(\"1. BASIC STATISTICS OVERVIEW:\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Financial statistics\n",
        "print(\"💰 FINANCIAL STATISTICS:\")\n",
        "print(f\"Average Budget: ${merged_df['budget'].mean():,.0f}\")\n",
        "print(f\"Average Revenue: ${merged_df['revenue'].mean():,.0f}\")\n",
        "print(f\"Average Profit: ${merged_df['profit'].mean():,.0f}\")\n",
        "print(f\"Highest Budget Movie: ${merged_df['budget'].max():,.0f}\")\n",
        "print(f\"Highest Revenue Movie: ${merged_df['revenue'].max():,.0f}\")\n",
        "\n",
        "# Rating statistics\n",
        "print(f\"\\n⭐ RATING STATISTICS:\")\n",
        "print(f\"Average Rating: {merged_df['vote_average'].mean():.2f}/10\")\n",
        "print(f\"Highest Rated Movie: {merged_df['vote_average'].max():.2f}/10\")\n",
        "print(f\"Average Runtime: {merged_df['runtime'].mean():.0f} minutes\")\n",
        "\n",
        "# 2. Distribution Analysis with Better Scaling\n",
        "print(\"\\n2. DISTRIBUTION ANALYSIS (Improved Scaling):\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Create subplots for distribution analysis\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "fig.suptitle('Movie Dataset Distribution Analysis (Improved Scaling)', fontsize=16, fontweight='bold')\n",
        "\n",
        "# Budget distribution - Log scale\n",
        "budget_data = merged_df['budget'].dropna()\n",
        "budget_data = budget_data[budget_data > 0]  # Remove zeros for log scale\n",
        "axes[0, 0].hist(np.log10(budget_data), bins=50, alpha=0.7, color='skyblue', edgecolor='black')\n",
        "axes[0, 0].set_title('Budget Distribution (Log Scale)')\n",
        "axes[0, 0].set_xlabel('Log10(Budget) - $1M to $100M')\n",
        "axes[0, 0].set_ylabel('Frequency')\n",
        "axes[0, 0].set_xticks([6, 7, 8])\n",
        "axes[0, 0].set_xticklabels(['$1M', '$10M', '$100M'])\n",
        "\n",
        "# Revenue distribution - Log scale\n",
        "revenue_data = merged_df['revenue'].dropna()\n",
        "revenue_data = revenue_data[revenue_data > 0]  # Remove zeros for log scale\n",
        "axes[0, 1].hist(np.log10(revenue_data), bins=50, alpha=0.7, color='lightgreen', edgecolor='black')\n",
        "axes[0, 1].set_title('Revenue Distribution (Log Scale)')\n",
        "axes[0, 1].set_xlabel('Log10(Revenue) - $1M to $1B')\n",
        "axes[0, 1].set_ylabel('Frequency')\n",
        "axes[0, 1].set_xticks([6, 7, 8, 9])\n",
        "axes[0, 1].set_xticklabels(['$1M', '$10M', '$100M', '$1B'])\n",
        "\n",
        "# Rating distribution - Keep as is (already good)\n",
        "axes[0, 2].hist(merged_df['vote_average'], bins=30, alpha=0.7, color='orange', edgecolor='black')\n",
        "axes[0, 2].set_title('Rating Distribution')\n",
        "axes[0, 2].set_xlabel('Rating (/10)')\n",
        "axes[0, 2].set_ylabel('Frequency')\n",
        "\n",
        "# Runtime distribution - Keep as is (already good)\n",
        "axes[1, 0].hist(merged_df['runtime'].dropna(), bins=40, alpha=0.7, color='pink', edgecolor='black')\n",
        "axes[1, 0].set_title('Runtime Distribution')\n",
        "axes[1, 0].set_xlabel('Runtime (minutes)')\n",
        "axes[1, 0].set_ylabel('Frequency')\n",
        "\n",
        "# Popularity distribution - Log scale\n",
        "popularity_data = merged_df['popularity']\n",
        "popularity_data = popularity_data[popularity_data > 0]  # Remove zeros for log scale\n",
        "axes[1, 1].hist(np.log10(popularity_data), bins=50, alpha=0.7, color='lightcoral', edgecolor='black')\n",
        "axes[1, 1].set_title('Popularity Distribution (Log Scale)')\n",
        "axes[1, 1].set_xlabel('Log10(Popularity) - 0.1 to 100')\n",
        "axes[1, 1].set_ylabel('Frequency')\n",
        "axes[1, 1].set_xticks([-1, 0, 1, 2])\n",
        "axes[1, 1].set_xticklabels(['0.1', '1', '10', '100'])\n",
        "\n",
        "# Genre count distribution - Keep as is (already good)\n",
        "axes[1, 2].hist(merged_df['genre_count'], bins=range(0, merged_df['genre_count'].max()+2),\n",
        "                alpha=0.7, color='lightblue', edgecolor='black')\n",
        "axes[1, 2].set_title('Number of Genres per Movie')\n",
        "axes[1, 2].set_xlabel('Number of Genres')\n",
        "axes[1, 2].set_ylabel('Frequency')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"✅ Distribution analysis with improved scaling completed!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10cc7b22",
      "metadata": {
        "id": "10cc7b22"
      },
      "outputs": [],
      "source": [
        "# Data Analysis and Visualization - Part 2: Genre Analysis and Time Trends\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"GENRE ANALYSIS AND TIME TRENDS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# 1. Genre Analysis\n",
        "print(\"1. GENRE ANALYSIS:\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Extract all genres\n",
        "all_genres = []\n",
        "for genres_list in merged_df['genres_parsed']:\n",
        "    if isinstance(genres_list, list):\n",
        "        all_genres.extend(genres_list)\n",
        "\n",
        "# Count genre frequency\n",
        "from collections import Counter\n",
        "genre_counts = Counter(all_genres)\n",
        "\n",
        "print(\"🎬 TOP 10 MOST COMMON GENRES:\")\n",
        "print(\"-\" * 30)\n",
        "for i, (genre, count) in enumerate(genre_counts.most_common(10), 1):\n",
        "    print(f\"{i:2d}. {genre:<20} ({count:3d} movies)\")\n",
        "\n",
        "# 2. Genre Visualization\n",
        "fig, axes = plt.subplots(1, 2, figsize=(20, 8))\n",
        "\n",
        "# Top 15 genres bar chart\n",
        "top_genres = dict(genre_counts.most_common(15))\n",
        "axes[0].barh(list(top_genres.keys()), list(top_genres.values()), color='steelblue', alpha=0.8)\n",
        "axes[0].set_title('Top 15 Movie Genres', fontsize=14, fontweight='bold')\n",
        "axes[0].set_xlabel('Number of Movies')\n",
        "axes[0].invert_yaxis()\n",
        "\n",
        "# Genre count distribution\n",
        "axes[1].hist(merged_df['genre_count'], bins=range(0, merged_df['genre_count'].max()+2),\n",
        "             color='lightgreen', alpha=0.8, edgecolor='black')\n",
        "axes[1].set_title('Distribution of Genre Count per Movie', fontsize=14, fontweight='bold')\n",
        "axes[1].set_xlabel('Number of Genres')\n",
        "axes[1].set_ylabel('Number of Movies')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 3. Time Analysis\n",
        "print(\"\\n2. TIME ANALYSIS:\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Movies by decade\n",
        "decade_counts = merged_df['decade'].value_counts().sort_index()\n",
        "print(\"📅 MOVIES BY DECADE:\")\n",
        "print(\"-\" * 25)\n",
        "for decade, count in decade_counts.items():\n",
        "    print(f\"{decade}s: {count:3d} movies\")\n",
        "\n",
        "# 4. Time Trends Visualization\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "# Movies by decade\n",
        "decade_counts.plot(kind='bar', ax=axes[0, 0], color='coral', alpha=0.8)\n",
        "axes[0, 0].set_title('Movies Released by Decade', fontweight='bold')\n",
        "axes[0, 0].set_xlabel('Decade')\n",
        "axes[0, 0].set_ylabel('Number of Movies')\n",
        "axes[0, 0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# Average rating by decade\n",
        "rating_by_decade = merged_df.groupby('decade')['vote_average'].mean()\n",
        "rating_by_decade.plot(kind='line', ax=axes[0, 1], marker='o', color='darkgreen', linewidth=2)\n",
        "axes[0, 1].set_title('Average Rating by Decade', fontweight='bold')\n",
        "axes[0, 1].set_xlabel('Decade')\n",
        "axes[0, 1].set_ylabel('Average Rating')\n",
        "axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "# Average budget by decade\n",
        "budget_by_decade = merged_df.groupby('decade')['budget'].mean()\n",
        "budget_by_decade.plot(kind='bar', ax=axes[1, 0], color='gold', alpha=0.8)\n",
        "axes[1, 0].set_title('Average Budget by Decade', fontweight='bold')\n",
        "axes[1, 0].set_xlabel('Decade')\n",
        "axes[1, 0].set_ylabel('Average Budget ($)')\n",
        "axes[1, 0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# Average revenue by decade\n",
        "revenue_by_decade = merged_df.groupby('decade')['revenue'].mean()\n",
        "revenue_by_decade.plot(kind='bar', ax=axes[1, 1], color='purple', alpha=0.8)\n",
        "axes[1, 1].set_title('Average Revenue by Decade', fontweight='bold')\n",
        "axes[1, 1].set_xlabel('Decade')\n",
        "axes[1, 1].set_ylabel('Average Revenue ($)')\n",
        "axes[1, 1].tick_params(axis='x', rotation=45)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"✅ Genre and time analysis completed!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1736fad7",
      "metadata": {
        "id": "1736fad7"
      },
      "outputs": [],
      "source": [
        "# Data Analysis and Visualization - Part 3: Correlation Analysis and Top Movies\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"CORRELATION ANALYSIS AND TOP MOVIES\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# 1. Correlation Analysis\n",
        "print(\"1. CORRELATION ANALYSIS:\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Select numerical columns for correlation\n",
        "numerical_cols = ['budget', 'revenue', 'profit', 'runtime', 'popularity',\n",
        "                  'vote_average', 'vote_count', 'genre_count']\n",
        "correlation_matrix = merged_df[numerical_cols].corr()\n",
        "\n",
        "print(\"🔗 KEY CORRELATIONS:\")\n",
        "print(\"-\" * 25)\n",
        "print(f\"Budget vs Revenue: {correlation_matrix.loc['budget', 'revenue']:.3f}\")\n",
        "print(f\"Budget vs Rating: {correlation_matrix.loc['budget', 'vote_average']:.3f}\")\n",
        "print(f\"Revenue vs Rating: {correlation_matrix.loc['revenue', 'vote_average']:.3f}\")\n",
        "print(f\"Popularity vs Rating: {correlation_matrix.loc['popularity', 'vote_average']:.3f}\")\n",
        "print(f\"Runtime vs Rating: {correlation_matrix.loc['runtime', 'vote_average']:.3f}\")\n",
        "\n",
        "# 2. Correlation Heatmap\n",
        "fig, axes = plt.subplots(1, 2, figsize=(20, 8))\n",
        "\n",
        "# Correlation heatmap\n",
        "import seaborn as sns\n",
        "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
        "sns.heatmap(correlation_matrix, mask=mask, annot=True, cmap='coolwarm', center=0,\n",
        "            square=True, ax=axes[0], cbar_kws={\"shrink\": .8})\n",
        "axes[0].set_title('Correlation Matrix Heatmap', fontsize=14, fontweight='bold')\n",
        "\n",
        "# Budget vs Revenue scatter plot\n",
        "scatter = axes[1].scatter(merged_df['budget'], merged_df['revenue'],\n",
        "                         c=merged_df['vote_average'], cmap='viridis', alpha=0.6)\n",
        "axes[1].set_xlabel('Budget ($)')\n",
        "axes[1].set_ylabel('Revenue ($)')\n",
        "axes[1].set_title('Budget vs Revenue (colored by Rating)', fontweight='bold')\n",
        "plt.colorbar(scatter, ax=axes[1], label='Rating')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 3. Top Movies Analysis\n",
        "print(\"\\n2. TOP MOVIES ANALYSIS:\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Top rated movies\n",
        "top_rated = merged_df.nlargest(10, 'vote_average')[['original_title', 'year', 'vote_average', 'genres_parsed']]\n",
        "print(\"🏆 TOP 10 HIGHEST RATED MOVIES:\")\n",
        "print(\"-\" * 40)\n",
        "for i, (idx, row) in enumerate(top_rated.iterrows(), 1):\n",
        "    genres = ', '.join(row['genres_parsed'][:2]) if row['genres_parsed'] else 'Unknown'\n",
        "    print(f\"{i:2d}. {row['original_title']:<30} ({row['year']}) - {row['vote_average']:.1f}/10 - {genres}\")\n",
        "\n",
        "# Top grossing movies\n",
        "top_grossing = merged_df.nlargest(10, 'revenue')[['original_title', 'year', 'revenue', 'budget', 'profit']]\n",
        "print(f\"\\n💰 TOP 10 HIGHEST GROSSING MOVIES:\")\n",
        "print(\"-\" * 45)\n",
        "for i, (idx, row) in enumerate(top_grossing.iterrows(), 1):\n",
        "    print(f\"{i:2d}. {row['original_title']:<30} ({row['year']}) - ${row['revenue']:,.0f}\")\n",
        "\n",
        "# Most profitable movies\n",
        "top_profitable = merged_df.nlargest(10, 'profit')[['original_title', 'year', 'profit', 'budget']]\n",
        "print(f\"\\n📈 TOP 10 MOST PROFITABLE MOVIES:\")\n",
        "print(\"-\" * 40)\n",
        "for i, (idx, row) in enumerate(top_profitable.iterrows(), 1):\n",
        "    print(f\"{i:2d}. {row['original_title']:<30} ({row['year']}) - ${row['profit']:,.0f} profit\")\n",
        "\n",
        "# 4. Top Movies Visualization\n",
        "fig, axes = plt.subplots(2, 2, figsize=(20, 12))\n",
        "\n",
        "# Top rated movies\n",
        "top_10_rated = merged_df.nlargest(10, 'vote_average')\n",
        "axes[0, 0].barh(range(len(top_10_rated)), top_10_rated['vote_average'], color='gold', alpha=0.8)\n",
        "axes[0, 0].set_yticks(range(len(top_10_rated)))\n",
        "axes[0, 0].set_yticklabels([title[:20] + '...' if len(title) > 20 else title\n",
        "                            for title in top_10_rated['original_title']], fontsize=8)\n",
        "axes[0, 0].set_title('Top 10 Highest Rated Movies', fontweight='bold')\n",
        "axes[0, 0].set_xlabel('Rating')\n",
        "\n",
        "# Top grossing movies\n",
        "top_10_grossing = merged_df.nlargest(10, 'revenue')\n",
        "axes[0, 1].barh(range(len(top_10_grossing)), top_10_grossing['revenue']/1e9, color='green', alpha=0.8)\n",
        "axes[0, 1].set_yticks(range(len(top_10_grossing)))\n",
        "axes[0, 1].set_yticklabels([title[:20] + '...' if len(title) > 20 else title\n",
        "                            for title in top_10_grossing['original_title']], fontsize=8)\n",
        "axes[0, 1].set_title('Top 10 Highest Grossing Movies', fontweight='bold')\n",
        "axes[0, 1].set_xlabel('Revenue (Billions $)')\n",
        "\n",
        "# Budget vs Rating scatter\n",
        "axes[1, 0].scatter(merged_df['budget']/1e6, merged_df['vote_average'], alpha=0.6, color='purple')\n",
        "axes[1, 0].set_xlabel('Budget (Millions $)')\n",
        "axes[1, 0].set_ylabel('Rating')\n",
        "axes[1, 0].set_title('Budget vs Rating', fontweight='bold')\n",
        "axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# Runtime vs Rating scatter\n",
        "axes[1, 1].scatter(merged_df['runtime'], merged_df['vote_average'], alpha=0.6, color='orange')\n",
        "axes[1, 1].set_xlabel('Runtime (minutes)')\n",
        "axes[1, 1].set_ylabel('Rating')\n",
        "axes[1, 1].set_title('Runtime vs Rating', fontweight='bold')\n",
        "axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"✅ Correlation analysis and top movies analysis completed!\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}